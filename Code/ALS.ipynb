{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ALS.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCOGBEO1UAqf"
      },
      "source": [
        "#  Alternating Least Square"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfLFPTj3uUhN"
      },
      "source": [
        "## NOTE\n",
        "Here we are using **PySpark API** for implementing recommendation using **ALS METHOD.**\n",
        "\n",
        "**PySpark** is the Python API written in python to support Apache Spark. Apache Spark is a distributed framework that can handle Big Data analysis. Spark is basically a computational engine, that works with huge sets of data by processing them in parallel and batch systems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3zTCGp-zQG_",
        "outputId": "3e8238f0-80ea-4ec5-9499-40b64ba51738"
      },
      "source": [
        "# Mounting drive to google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h27IRogFQ9q2"
      },
      "source": [
        "\n",
        "### Downloading Dependancies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu4il9PVzmkO"
      },
      "source": [
        "Spark is written in the Scala programming language and requires the Java Virtual Machine (JVM) to run. Therefore, our first task is to download Java."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW0kK_SPv9N1"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj6tbqsKzy6I"
      },
      "source": [
        "Next, we will install Apache Spark 3.0.1 with Hadoop 2.7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fFyZ1X-z4AO"
      },
      "source": [
        "!wget -q ftp://mirror.klaus-uwe.me/apache/spark/spark-2.4.7/spark-2.4.7-bin-hadoop2.7.tgz"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERmurZGnz6yN"
      },
      "source": [
        "Now, we just need to unzip that folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QNMy_UMz-kA"
      },
      "source": [
        "!tar xf spark-2.4.7-bin-hadoop2.7.tgz"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy6DMnbB0Cf-"
      },
      "source": [
        "There is one last thing that we need to install and that is the findspark library. It will locate Spark on the system and import it as a regular library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs1SKHLN1zyf"
      },
      "source": [
        "!pip install -q findspark"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N81RMG5F36ro",
        "outputId": "14d26792-3ca9-450b-9a51-84f14efdf88a"
      },
      "source": [
        "!pip install py4j"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting py4j\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/e2/543019a6e620b759a59f134158b4595766f9bf520a1081a2ba1a1809ba32/py4j-0.10.9.2-py2.py3-none-any.whl (198kB)\n",
            "\r\u001b[K     |█▋                              | 10kB 19.8MB/s eta 0:00:01\r\u001b[K     |███▎                            | 20kB 26.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 30.4MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 40kB 33.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 51kB 31.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 61kB 23.1MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 71kB 23.3MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 81kB 18.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 92kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 102kB 20.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 112kB 20.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 122kB 20.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 133kB 20.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 143kB 20.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 153kB 20.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 163kB 20.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 174kB 20.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 184kB 20.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 194kB 20.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 20.5MB/s \n",
            "\u001b[?25hInstalling collected packages: py4j\n",
            "Successfully installed py4j-0.10.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWg7qQui2CRF"
      },
      "source": [
        "Now that we have installed all the necessary dependencies in Colab, it is time to set the environment path. This will enable us to run Pyspark in the Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o2PV6P8t9Cq"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.7-bin-hadoop2.7\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xUbl6GfUuXAm",
        "outputId": "62552d29-08b4-4643-eb05-760d842e7ac0"
      },
      "source": [
        "import findspark\n",
        "findspark.find() #To find folder of SPARK HOME"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/spark-2.4.7-bin-hadoop2.7'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GqUF4962NsM"
      },
      "source": [
        "import findspark\n",
        "# findspark.find() =To find folder of SPARK HOME\n",
        "findspark.init(\"/content/spark-2.4.7-bin-hadoop2.7\")# SPARK_HOME"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqYqQndP2Muh"
      },
      "source": [
        "We need to locate Spark in the system. For that, we import findspark and use the findspark.init() method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQL9_CaCu5jG"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWbskSZ_UAq0"
      },
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql.functions import col, explode\n",
        "from pyspark import SparkContext"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6cvbVeR6-5F"
      },
      "source": [
        "### Starting the SPARK Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSKY7eoB0dWt"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "sc = SparkContext\n",
        "# sc.setCheckpointDir('checkpoint')\n",
        "spark = SparkSession.builder.appName('Recommendations').getOrCreate()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csM2LrbsvMrY"
      },
      "source": [
        "# path config\n",
        "# /content/drive/MyDrive/ml-latest\n",
        "data_path = '/content/drive/MyDrive/'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YD6Sv7j7H97"
      },
      "source": [
        "### Path configuration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOA3uw4081R9"
      },
      "source": [
        "### Loading the data in the Colab from drive "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aluKZ6gGzi3z"
      },
      "source": [
        "movies = spark.read.csv(data_path+'ml-latest-small/movies.csv', header=True)\n",
        "ratings = spark.read.csv(data_path+'ml-latest-small/ratings.csv',  header=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aB_WkgYJ0tt0",
        "outputId": "19e76c36-ffd2-4efb-b0be-dc8234e56e94"
      },
      "source": [
        "ratings = ratings.drop('Timestamp')\n",
        "ratings = ratings.withColumn('UserID', col('UserID').cast('integer'))\n",
        "ratings = ratings.withColumn('MovieID', col('MovieID').cast('integer'))\n",
        "ratings = ratings.withColumn('Rating', col('rating').cast('float'))\n",
        "ratings.limit(10).show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+------+\n",
            "|UserID|MovieID|Rating|\n",
            "+------+-------+------+\n",
            "|     1|      1|   4.0|\n",
            "|     1|      3|   4.0|\n",
            "|     1|      6|   4.0|\n",
            "|     1|     47|   5.0|\n",
            "|     1|     50|   5.0|\n",
            "|     1|     70|   3.0|\n",
            "|     1|    101|   5.0|\n",
            "|     1|    110|   4.0|\n",
            "|     1|    151|   5.0|\n",
            "|     1|    157|   5.0|\n",
            "+------+-------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XakvmY-E4cSU"
      },
      "source": [
        "## Calculating sparsity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "180ncwU10-DE",
        "outputId": "9fe6228c-d7cf-469c-f8e0-74222959647a"
      },
      "source": [
        "numerator = ratings.select(\"Rating\").count()\n",
        "\n",
        "# Count the number of distinct userIds and distinct movieIds\n",
        "unique_users = ratings.select(\"UserID\").distinct().count()\n",
        "unique_movies = ratings.select(\"MovieID\").distinct().count()\n",
        "\n",
        "# Set the denominator equal to the number of users multiplied by the number of movies\n",
        "denominator = unique_users * unique_movies\n",
        "\n",
        "# Divide the numerator by the denominator\n",
        "sparsity = (1.0 - (numerator *1.0)/denominator)*100\n",
        "print(\"The ratings data is \", \"%.2f\" % sparsity + \"% empty.\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The ratings data is  98.30% empty.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2_zGABu4jj-"
      },
      "source": [
        "## Interpreting Ratings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D58_w7tV1A3j",
        "outputId": "a3f9b00d-01c3-4cdd-d2f4-65ae151db6a0"
      },
      "source": [
        "# Group data by userId, count ratings\n",
        "UserID_pivot = ratings.groupBy(\"UserID\").count().orderBy('count', ascending=False)\n",
        "UserID_pivot.limit(10).show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "|UserID|count|\n",
            "+------+-----+\n",
            "|   414| 2698|\n",
            "|   599| 2478|\n",
            "|   474| 2108|\n",
            "|   448| 1864|\n",
            "|   274| 1346|\n",
            "|   610| 1302|\n",
            "|    68| 1260|\n",
            "|   380| 1218|\n",
            "|   606| 1115|\n",
            "|   288| 1055|\n",
            "+------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyG-noM01F0E",
        "outputId": "ccedf588-7862-4519-e253-90da8a23f949"
      },
      "source": [
        "# Group data by userId, count ratings\n",
        "MovieID_pivot = ratings.groupBy(\"MovieID\").count().orderBy('count', ascending=False)\n",
        "MovieID_pivot.limit(10).show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----+\n",
            "|MovieID|count|\n",
            "+-------+-----+\n",
            "|    356|  329|\n",
            "|    318|  317|\n",
            "|    296|  307|\n",
            "|    593|  279|\n",
            "|   2571|  278|\n",
            "|    260|  251|\n",
            "|    480|  238|\n",
            "|    110|  237|\n",
            "|    589|  224|\n",
            "|    527|  220|\n",
            "+-------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsKx9ATc9pZu"
      },
      "source": [
        "# Implementing ALS(Alternating Least Square) algorithm in Spark "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60EmM1jL-A-s"
      },
      "source": [
        "The approach is generally divided into 4 basic steps.\n",
        "1. Load the data\n",
        "2. Spliting data : train,validation,test\n",
        "3. ALS model and evaluation\n",
        "4. Test the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh23aZeM-n-2"
      },
      "source": [
        "### 1. Load the Data\n",
        "\n",
        "Import libraries that are needed "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLoY-6qh1JDs"
      },
      "source": [
        "# Import the required functions\n",
        "\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqSvUA6iCUaI"
      },
      "source": [
        "### 2. Spliting the data\n",
        "\n",
        "We Split the data using randomSplit() function in spark. \n",
        "\n",
        "To divide the data into train and test data, we divide them in 7:3 ratio respectively.\n",
        "\n",
        "\n",
        "Spark allows users to set the coldStartStrategy parameter to “drop” in order to drop any rows in the DataFrame of predictions that contain NaN values. The evaluation metric will then be computed over the non-NaN data and will be valid\n",
        "\n",
        "implicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data (defaults to false which means using explicit feedback)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH14QLpm1S0A"
      },
      "source": [
        "# Create test and train set\n",
        "(train, test) = ratings.randomSplit([0.8, 0.2], seed = 1234)\n",
        "\n",
        "# Create ALS model\n",
        "als = ALS(userCol=\"UserID\", itemCol=\"MovieID\", ratingCol=\"Rating\", nonnegative = True, implicitPrefs = False\n",
        "          , coldStartStrategy=\"drop\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac_V27buQlOZ"
      },
      "source": [
        "### 3. ALS model and evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_D0NDpN5Epc"
      },
      "source": [
        "#### Tune the ALS model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOYogLfl1WeM",
        "outputId": "092e2f3c-bd3f-4fb0-df57-ad20407e0ee3"
      },
      "source": [
        "# Add hyperparameters and their respective values to param_grid\n",
        "param_grid = ParamGridBuilder() \\\n",
        "            .addGrid(als.rank, [10, 50, 100, 150]) \\\n",
        "            .addGrid(als.regParam, [.01, .05, .1, .15]) \\\n",
        "            .build()\n",
        "            #             .addGrid(als.maxIter, [5, 50, 100, 200]) \\\n",
        "\n",
        "           \n",
        "# Define evaluator as RMSE and print length of evaluator\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"Rating\", predictionCol=\"prediction\") \n",
        "print (\"Num models to be tested: \", len(param_grid))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num models to be tested:  16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-Qhm2mJ5RB4"
      },
      "source": [
        "#### Build your cross validation pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHmJBXEI1Z4V"
      },
      "source": [
        "# Build cross validation using CrossValidator\n",
        "# numFolds=3 means the CrossValidator will create 3 different models.\n",
        "cv = CrossValidator(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=3)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlZzMSOP5VWU"
      },
      "source": [
        "#### Obtain Best Model and Best Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2NF87vr1heX"
      },
      "source": [
        "# We fit the cross validator to the 'train' dataset\n",
        "model = cv.fit(train)\n",
        "\n",
        "# We Extract best model from the cv model above\n",
        "best_model = model.bestModel"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv4CijS_xGjf"
      },
      "source": [
        "params = [{p.name: v for p, v in m.items()} for m in cv.getEstimatorParamMaps()]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvba8wFM1lFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb03a6bc-321e-44df-b4fe-df2ee39856c4"
      },
      "source": [
        "# Print best_model\n",
        "print(type(best_model))\n",
        "\n",
        "# Complete the code below to extract the ALS model parameters\n",
        "print(\"**Best Model**\")\n",
        "\n",
        "# # Print \"Rank\"\n",
        "print(\"  Rank:\", best_model._java_obj.parent().getRank())\n",
        "\n",
        "# Print \"MaxIter\"\n",
        "print(\"  MaxIter:\", best_model._java_obj.parent().getMaxIter())\n",
        "\n",
        "# Print \"RegParam\"\n",
        "print(\"  RegParam:\", best_model._java_obj.parent().getRegParam())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pyspark.ml.recommendation.ALSModel'>\n",
            "**Best Model**\n",
            "  Rank: 100\n",
            "  MaxIter: 10\n",
            "  RegParam: 0.15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD9goVXjjabq"
      },
      "source": [
        "### 4. Test the Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOR9o9R6jlxd"
      },
      "source": [
        "Test and evaluate the final model by calculating the RMSE of model for best hyperparameters i.e. number of iterations, latent factors and regularization parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffyWkTMz1poh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd6daa44-016b-4fdb-9ae9-ec7c68c6acdb"
      },
      "source": [
        "# View the predictions\n",
        "test_predictions = best_model.transform(test)\n",
        "RMSE = evaluator.evaluate(test_predictions)\n",
        "print(RMSE)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.865499666447013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AnVzVvX1sZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d629d6cc-d0fa-4a48-ed18-eaeaeb9fd1b9"
      },
      "source": [
        "test_predictions.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+------+----------+\n",
            "|UserID|MovieID|Rating|prediction|\n",
            "+------+-------+------+----------+\n",
            "|   385|    471|   4.0| 3.2199137|\n",
            "|   462|    471|   2.5|   2.49348|\n",
            "|   387|    471|   3.0| 2.9785595|\n",
            "|   171|    471|   3.0|  4.435947|\n",
            "|    32|    471|   3.0| 3.7408144|\n",
            "|   469|    471|   5.0|  3.454264|\n",
            "|   357|    471|   3.5| 3.9528108|\n",
            "|   132|   1088|   4.0| 2.7562292|\n",
            "|   563|   1088|   4.0| 3.3933873|\n",
            "|   594|   1088|   4.5| 4.1311927|\n",
            "|   307|   1088|   3.0| 2.3777387|\n",
            "|    51|   1088|   4.0|  3.604006|\n",
            "|   221|   1088|   3.0| 3.0407107|\n",
            "|   414|   1088|   3.0| 3.0470037|\n",
            "|   200|   1088|   4.0|  3.690107|\n",
            "|   104|   1088|   3.0| 3.6271515|\n",
            "|    19|   1238|   3.0|  3.203387|\n",
            "|   156|   1238|   4.0| 4.0440884|\n",
            "|   425|   1342|   3.5|   2.22978|\n",
            "|   600|   1342|   2.5| 2.0980847|\n",
            "+------+-------+------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpvZ6QmaerAy",
        "outputId": "a1bfdfa9-a0dd-4b3e-f680-b69b363e3ca1"
      },
      "source": [
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "def somefunc1(value1):\n",
        "  if   value1<3: \n",
        "      return 0\n",
        "  else:\n",
        "      return 1\n",
        "\n",
        "\n",
        "def somefunc2(value1,value2):\n",
        "  if   value1 == value2: \n",
        "      return 1\n",
        "  else:\n",
        "      return 0      \n",
        "#convert to a UDF Function by passing in the function and return type of function\n",
        "\n",
        "udfsomefunc1 = F.udf(somefunc1, IntegerType())\n",
        "udfsomefunc2 = F.udf(somefunc2, IntegerType())\n",
        "ratings_1 = test_predictions.withColumn(\"Rating_binary\", udfsomefunc1(\"Rating\"))\n",
        "ratings_2 = ratings_1.withColumn(\"predictions_binary\", udfsomefunc1(\"prediction\"))\n",
        "ratings_with_high_low = ratings_2.withColumn(\"Truth\", udfsomefunc2(\"Rating_binary\",\"predictions_binary\"))\n",
        "ratings_with_high_low.show()\n",
        "# ratings_1.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------+------+----------+-------------+------------------+-----+\n",
            "|UserID|MovieID|Rating|prediction|Rating_binary|predictions_binary|Truth|\n",
            "+------+-------+------+----------+-------------+------------------+-----+\n",
            "|   385|    471|   4.0| 3.2199137|            1|                 1|    1|\n",
            "|   462|    471|   2.5|   2.49348|            0|                 0|    1|\n",
            "|   387|    471|   3.0| 2.9785595|            1|                 0|    0|\n",
            "|   171|    471|   3.0|  4.435947|            1|                 1|    1|\n",
            "|    32|    471|   3.0| 3.7408144|            1|                 1|    1|\n",
            "|   469|    471|   5.0|  3.454264|            1|                 1|    1|\n",
            "|   357|    471|   3.5| 3.9528108|            1|                 1|    1|\n",
            "|   132|   1088|   4.0| 2.7562292|            1|                 0|    0|\n",
            "|   563|   1088|   4.0| 3.3933873|            1|                 1|    1|\n",
            "|   594|   1088|   4.5| 4.1311927|            1|                 1|    1|\n",
            "|   307|   1088|   3.0| 2.3777387|            1|                 0|    0|\n",
            "|    51|   1088|   4.0|  3.604006|            1|                 1|    1|\n",
            "|   221|   1088|   3.0| 3.0407107|            1|                 1|    1|\n",
            "|   414|   1088|   3.0| 3.0470037|            1|                 1|    1|\n",
            "|   200|   1088|   4.0|  3.690107|            1|                 1|    1|\n",
            "|   104|   1088|   3.0| 3.6271515|            1|                 1|    1|\n",
            "|    19|   1238|   3.0|  3.203387|            1|                 1|    1|\n",
            "|   156|   1238|   4.0| 4.0440884|            1|                 1|    1|\n",
            "|   425|   1342|   3.5|   2.22978|            1|                 0|    0|\n",
            "|   600|   1342|   2.5| 2.0980847|            0|                 0|    1|\n",
            "+------+-------+------+----------+-------------+------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oe9GL9GOoYOf",
        "outputId": "39dca71e-e2c5-425e-87f9-7b3393557699"
      },
      "source": [
        "Perf_values = ratings_with_high_low.groupBy(\"Truth\").count().orderBy('count', ascending=False)\n",
        "Perf_values.limit(6).show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-----+\n",
            "|Truth|count|\n",
            "+-----+-----+\n",
            "|    1|15016|\n",
            "|    0| 4396|\n",
            "+-----+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTP6r1vKrkEp",
        "outputId": "1f35ef07-d4e3-459f-fa41-4e431e068307"
      },
      "source": [
        "a=list(Perf_values.select('Truth').toPandas()['Truth']) \n",
        "b=list(Perf_values.select('count').toPandas()['count'])\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 0]\n",
            "[15016, 4396]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CliUO5zusFIs",
        "outputId": "0310376b-9461-4f2c-dafd-b719817f8de3"
      },
      "source": [
        "accuracy=b[0]/(b[0]+b[1])\n",
        "print(accuracy*100)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "77.35421388831651\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgmJuO9wlG4V"
      },
      "source": [
        "# Recommending Movies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBrX4xRNl33l"
      },
      "source": [
        "The final part of our code comes i.e. predicting the best movies for the user based on personalized choice and recommending the movies to the user. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nTCD0Jw13UU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ed654df-4448-40c6-cbd7-4d29e807afd1"
      },
      "source": [
        "# Generate n Recommendations for all users\n",
        "recommendations = best_model.recommendForAllUsers(10)\n",
        "recommendations.limit(10).show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+--------------------+\n",
            "|UserID|     recommendations|\n",
            "+------+--------------------+\n",
            "|   471|[[3379, 4.6720667...|\n",
            "|   463|[[3379, 4.7757664...|\n",
            "|   496|[[26326, 4.422524...|\n",
            "|   148|[[77846, 4.412014...|\n",
            "|   540|[[3379, 5.3685517...|\n",
            "|   392|[[3379, 4.6377344...|\n",
            "|   243|[[86237, 5.383588...|\n",
            "|    31|[[8477, 5.0337596...|\n",
            "|   516|[[4429, 4.7545447...|\n",
            "|   580|[[3379, 4.667716]...|\n",
            "+------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR6-azWoUArK"
      },
      "source": [
        "recommendations = recommendations\\\n",
        "    .withColumn(\"rec_exp\", explode(\"recommendations\"))\\\n",
        "    .select('userId', col(\"rec_exp.movieId\"), col(\"rec_exp.rating\"))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5-M5GnsHXTQ"
      },
      "source": [
        "##### 50th User’s Actual Preference:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZaEqZ612IMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc6f3665-9e61-4522-eb6a-9c0e05fff5a7"
      },
      "source": [
        "ratings.join(movies, on='MovieID').filter('UserID = 50').sort('Rating', ascending=False).limit(10).show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------+------+--------------------+--------------------+\n",
            "|MovieID|UserID|Rating|               title|              genres|\n",
            "+-------+------+------+--------------------+--------------------+\n",
            "|   1251|    50|   4.5|   8 1/2 (8½) (1963)|       Drama|Fantasy|\n",
            "|    924|    50|   4.5|2001: A Space Ody...|Adventure|Drama|S...|\n",
            "|   1204|    50|   4.5|Lawrence of Arabi...| Adventure|Drama|War|\n",
            "|   1208|    50|   4.5|Apocalypse Now (1...|    Action|Drama|War|\n",
            "|   1136|    50|   4.0|Monty Python and ...|Adventure|Comedy|...|\n",
            "|    903|    50|   4.0|      Vertigo (1958)|Drama|Mystery|Rom...|\n",
            "|   1199|    50|   4.0|       Brazil (1985)|      Fantasy|Sci-Fi|\n",
            "|    750|    50|   4.0|Dr. Strangelove o...|          Comedy|War|\n",
            "|   1201|    50|   4.0|Good, the Bad and...|Action|Adventure|...|\n",
            "|    899|    50|   4.0|Singin' in the Ra...|Comedy|Musical|Ro...|\n",
            "+-------+------+------+--------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noXCS9RsHUUK"
      },
      "source": [
        "##### 50th User’s ALS Recommentions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpm8A7YH17Ua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eed78ca3-76b7-41d9-f190-fc3840421a4b"
      },
      "source": [
        "recommendations.join(movies, on='MovieID').filter('UserID = 50').show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------+---------+--------------------+-----------------+\n",
            "|movieId|userId|   rating|               title|           genres|\n",
            "+-------+------+---------+--------------------+-----------------+\n",
            "|   3379|    50|3.8758972| On the Beach (1959)|            Drama|\n",
            "|  26326|    50|3.7777364|Holy Mountain, Th...|            Drama|\n",
            "|   7748|    50|3.7236607|Pierrot le fou (1...|      Crime|Drama|\n",
            "|   8477|    50|3.6442552|    Jetée, La (1962)|   Romance|Sci-Fi|\n",
            "|   7767|    50|3.6171787|Best of Youth, Th...|            Drama|\n",
            "|   1178|    50| 3.598996|Paths of Glory (1...|        Drama|War|\n",
            "|   8405|    50| 3.583364|Hour of the Wolf ...|     Drama|Horror|\n",
            "|   5747|    50|3.5750237|    Gallipoli (1981)|        Drama|War|\n",
            "| 132333|    50|3.5724738|         Seve (2014)|Documentary|Drama|\n",
            "|   5490|    50|3.5724738|  The Big Bus (1976)|    Action|Comedy|\n",
            "+-------+------+---------+--------------------+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}